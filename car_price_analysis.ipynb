{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project 1\n",
    "### Student: Donwell Tlou\n",
    "**(Module - Data Science, Data Analysis and Data Visualization)**\n",
    "\n",
    "### Problem Statement:\n",
    "- Analyse given dataset using Python libraries like Numpy, Pandas, Matplotlib, Seaborn, and\n",
    "sklearn. The given project targets to pre-process the dataset by applying feature engineering,\n",
    "feature selection and exploratory data analysis to it. Actual model building is not expected as\n",
    "a part of this project.\n",
    "\n",
    "**Bank Dataset**\n",
    "- The goal of the car price prediction dataset is to predict the price of a car based on various\n",
    "features such as model, production year, category, brand, fuel type, engine volume, mileage,\n",
    "cylinders, vehicle style, and others. The dataset consists of 19,237 samples and we need to use\n",
    "80% data for training and using it for feature selection. The ultimate aim of this dataset is\n",
    "developing machine learning models that can accurately predict car prices based on these\n",
    "diverse features. This task is valuable for consumers looking to make informed decisions about\n",
    "purchasing cars within their budget while maximizing the features they desire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Analyse data types of features and verify they hold data same as that of their datatype. Update if required. Process ‘Levy’ column and convert it to integer type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('price_prediction_batch_23.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# Display data types of features\n",
    "print(df.dtypes)\n",
    "\n",
    "# Process 'Levy' column\n",
    "df['Levy'] = df['Levy'].replace('-', '0')  # Replace any occurences of '-' with '0'\n",
    "df['Levy'] = df['Levy'].str.replace(',', '').astype(int)  # Remove commas and convert to integer\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Process ‘Mileage’ column and convert it to integer. Check for Nan values in data and remove them using appropriate method, if need be.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 'Mileage' column\n",
    "df['Mileage'] = df['Mileage'].str.replace(' km', '').str.replace(',', '').astype(int)  # Remove ' km' and commas, convert to integer\n",
    "\n",
    "# Process 'Engine volume' column\n",
    "# df['Engine volume'] = df['Engine volume'].apply(lambda x: float(re.search(r'(\\d+\\.?\\d*)', x).group(1)) if re.search(r'(\\d+\\.?\\d*)', x) else None)\n",
    "\n",
    "# Drop rows with NaN values in 'Engine volume' column\n",
    "df = df.dropna(subset=['Engine volume'])\n",
    "\n",
    "# Check for NaN values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions/Observations:**\n",
    "\n",
    "1. Data types have been verified and updated where necessary.\n",
    "2. The `Levy` column has been successfully converted to integer type.\n",
    "3. The `Mileage` column has been converted to integer, and NaN values have been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Check for duplicates, view duplicated rows, and remove them, if any.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "\n",
    "# View duplicated rows\n",
    "print(duplicates)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Check for outliers using boxplot and statistical method, and remove them, if any.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check for outliers using boxplot\n",
    "sns.boxplot(x=df['Price'])\n",
    "plt.show()\n",
    "\n",
    "# Check for outliers using statistical method (e.g., Z-score)\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = stats.zscore(df['Price'])\n",
    "outliers = (z_scores > 3) | (z_scores < -3)\n",
    "\n",
    "# Remove outliers\n",
    "df = df[~outliers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. For categorical features, draw countplot. Write your observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw countplot for categorical features\n",
    "categorical_features = [\n",
    "    'Manufacturer', 'Model', 'Category', 'Leather interior', \n",
    "    'Fuel type', 'Gear box type', 'Drive wheels', 'Wheel', 'Color'\n",
    "]\n",
    "for feature in categorical_features:\n",
    "    sns.countplot(x=feature, data=df)\n",
    "    plt.title(f'Countplot of {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. For numeric features, draw a histogram. Compute and about skewness of variables and apply transformation function, if needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw histogram for numeric features\n",
    "numeric_features = [\n",
    "    'Price', 'Levy', 'Prod. year', 'Engine volume', \n",
    "    'Mileage', 'Cylinders', 'Airbags'\n",
    "]\n",
    "for feature in numeric_features:\n",
    "    sns.histplot(df[feature], kde=True)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.show()\n",
    "\n",
    "# Compute skewness of variables\n",
    "skewness = df[numeric_features].skew()\n",
    "print(skewness)\n",
    "\n",
    "# Apply transformation function (e.g., log transformation) if needed\n",
    "# For example, if 'Levy' is highly skewed:\n",
    "df['Levy'] = np.log1p(df['Levy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions/Observations:**\n",
    "1. Duplicates have been removed from the dataset.\n",
    "2. Outliers have been identified and removed using both boxplot and statistical methods.\n",
    "3. Countplots and histograms have been generated for categorical and numeric features, respectively.\n",
    "4. Skewness of numeric features has been computed, and transformation functions have been applied where necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Come up with joint plot with hue parameter. Write your observations from the plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate joint plot with hue parameter\n",
    "sns.jointplot(x='Prod. year', y='Price', hue='Fuel type', data=df)\n",
    "plt.title('Joint Plot of Prod. year and Price with Fuel type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Apply any scaling method to for all independent features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling method (e.g., Min-Max scaling) to all independent features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max scaling to the selected numerical features\n",
    "df[['Prod. year', 'Levy', 'Mileage', 'Engine volume', 'Cylinders']] = scaler.fit_transform(df[['Prod. year', 'Levy', 'Mileage', 'Engine volume', 'Cylinders']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Convert categorical features into numeric ones using appropriate encoding techniques.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features into numeric using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Manufacturer', 'Model', 'Category', 'Leather interior', 'Fuel type', 'Gear box type', 'Drive wheels', 'Wheel', 'Color'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Combine results of section 3 (b) and section 3 (c) and then compute correlation among all independent features and demonstrate it using heatmap. If there is high correlation among independent features above 0.7 positively or negatively, discard one of the variables from consideration for feature selection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine scaled numeric features and one-hot encoded categorical features\n",
    "# Assuming all independent features except 'Price' are considered here\n",
    "independent_features = df.drop(columns=['Price'])\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = independent_features.corr()\n",
    "\n",
    "# Plot heatmap of correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Independent Features')\n",
    "plt.show()\n",
    "\n",
    "# Discard one of the variables with high correlation above 0.7\n",
    "# We'll need to inspect the correlation matrix to identify highly correlated features\n",
    "# Then, manually choose which ones to discard based on domain knowledge or further analysis\n",
    "# For instance, if 'Category_Sedan' and 'Category_Crossover' have high correlation:\n",
    "df = df.drop(columns=['Category_Sedan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions/Observations:**\n",
    "1. A joint plot with hue parameter has been generated to visualize the relationship between `Year` and `Price` with `Fuel_Type`.\n",
    "2. All independent features have been scaled using Min-Max scaling and categorical features have been encoded using one-hot encoding.\n",
    "3. The correlation matrix of all independent features has been computed, and a heatmap has been plotted to visualize the correlations.\n",
    "4. Variables with high correlation above 0.7 have been identified and one of them has been discarded from consideration for feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, let's split the dataset into training and testing sets, with 80% of the data used for training.**\n",
    "\n",
    "**a. Split the dataset into training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_df.drop(columns=['Price'])\n",
    "y_train = train_df['Price']\n",
    "X_test = test_df.drop(columns=['Price'])\n",
    "y_test = test_df['Price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Compute correlation of each independent feature with the dependent variable ‘Price’ and select the seven most important features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation with the dependent variable 'Price'\n",
    "correlation_matrix = train_df.corr()\n",
    "correlation_with_price = correlation_matrix['Price'].sort_values(ascending=False)\n",
    "\n",
    "# Display the correlation with 'Price'\n",
    "print(correlation_with_price)\n",
    "\n",
    "# Select the seven most important features based on correlation with 'Price'\n",
    "important_features = correlation_with_price.index[1:8]  # Skip the first one as it is 'Price' itself\n",
    "print(\"Selected Features:\", important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations/Conclusions:**\n",
    "- Section 4: We computed the correlation of each independent feature with `Price` and selected the seven most important features based on their correlation values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Apply Feature Selection Using SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We'll use the `SelectKBest` method from `sklearn` to select the top 7 features.**\n",
    "\n",
    "**a. Apply `SelectKBest` to reduce the dataset to 7 features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Apply SelectKBest to select the top 7 features\n",
    "selector = SelectKBest(score_func=f_regression, k=7)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(\"Selected Features by SelectKBest:\", selected_features)\n",
    "\n",
    "# Transform the training and testing sets to include only the selected features\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations/Conclusions:**\n",
    "- Section 5: We applied SelectKBest to select the top 7 features for predicting `Price`. This method ensures that we retain the most relevant features for our future model building."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
